# -*- coding: utf-8 -*-
"""exp1nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z1rnhXI1gQ6DIl9R-HCBk2qjbDued4zO
"""

!pip install nltk

import nltk
from nltk.tokenize import word_tokenize, sent_tokenize, WordPunctTokenizer,regexp_tokenize

nltk.download('punkt')

sample_text = "Hello! ðŸ˜ƒ How are you?let's talk Anshmita, Anshmita is a legend , who born to shine because Anshmita means the ray of sunlight.she stays cool-clam everytime."

words = word_tokenize(sample_text)
print("Word Tokenization:")
print(words)
print()

sentences = sent_tokenize(sample_text)
print("Sentence Tokenization:")
print(sentences)
print()

custom_tokenizer = WordPunctTokenizer()
custom_tokens = custom_tokenizer.tokenize(sample_text)
print("Custom Tokenization (handling punctuation):")
print(custom_tokens)

pattern = r'\w+'
regexp_tokens = regexp_tokenize(sample_text, pattern)
print("\nRegexp Tokenization:")
print(regexp_tokens)

def custom_split_tokenization(word_list):
    split_tokens = []
    for word in word_list:
        split_tokens.extend(word.split('-'))
    return split_tokens

split_tokens = custom_split_tokenization(words)
print("\nCustom Split Tokenization:")
print(split_tokens)